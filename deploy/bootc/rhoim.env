# RHOIM Environment Variables for bootc Model Serving

# --- Core Paths and Configuration (Used by Containerfile and Initializer) ---
MODEL_ID="TinyLlama/TinyLlama-1.1B-Chat-v1.0"
MODEL_PATH="/opt/models"
VLLM_PORT="8000"
VLLM_HOST="0.0.0.0"

# --- VLLM/Device Configuration ---
# Set to "cpu" for CPU mode (local testing) or "cuda" for NVIDIA GPU mode (production)
# 
# This can be overridden at runtime in several ways:
# 1. Edit this file (/etc/sysconfig/rhoim) and restart the service
# 2. Use systemd override: systemctl edit rhoim-vllm.service (add Environment="VLLM_DEVICE_TYPE=cuda")
# 3. Set at bootc install time: bootc install --env VLLM_DEVICE_TYPE=cuda ...
#
# Assumes NVIDIA GPUs only - other GPU types are not supported
# This controls all device-related settings automatically
# Default: "cpu" (safe for environments without GPU)
VLLM_DEVICE_TYPE="cpu"

# Optional: Override specific vLLM settings if needed
# VLLM_LOGGING_LEVEL=DEBUG
# VLLM_USE_FLASHINFER=0

# --- Gateway/API Configuration (Used by rhoim-gateway.service) ---
API_KEYS="devkey1,devkey2"
# BASE_PATH=/ # (If used by your gateway)
# ENABLE_RHOAI_ALIAS=true # (If used by your gateway)